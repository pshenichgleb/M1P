| Название | Год | Автор | Ссылка | Краткое содержание |
|----------|-----|-------|--------|-------------------|
| Stack More LLM's: Efficient Detection of Machine-Generated Texts via Perplexity Approximation | 2023 | G. M. Gritsaia, I. A. Khabutdinova, A. V. Grabovoya | [link](https://link.springer.com/article/10.1134/S1064562424602075) | Эффективный метод детекции машинно-генерированных текстов с использованием аппроксимации перплексии - можем сравнить |
| N-Gram Perplexity-Based AI-Generated Text Detection | 2024 | Poimanov Dmitrii, L. Mestetsky, A. Grabovoy | [link](https://www.researchgate.net/publication/389443848_N-Gram_Perplexity-Based_AI-Generated_Text_Detection) | Детекция ИИ-генерированных текстов на основе N-граммовой перплексии - можем сравнить |
| Findings of the The RuATD Shared Task 2022 on Artificial Text Detection in Russian | 2022 | Nikita Kondratev et al. | [link](https://arxiv.org/abs/2206.01583) | Результаты соревнования по детекции искусственных текстов на русском языке - можем сравнить |
| A Survey on LLM-Generated Text Detection: Necessity, Methods, and Future Directions | 2024 | Xianjun Yang et al. | [link](https://direct.mit.edu/coli/article/51/1/275/127462/A-Survey-on-LLM-Generated-Text-Detection-Necessity) | Комплексный обзор методов детекции LLM-генерированных текстов - не можем сравнить |
| AI-generated Text Detection: A Multifaceted Approach to Binary and Multiclass Classification | 2024 | Dimitris Tsagkos et al. | [link](https://arxiv.org/html/2505.11550v1) | Многоаспектный подход к бинарной и многоклассовой классификации ИИ-генерированных текстов - можем сравнить |
| Evaluating the efficacy of AI content detection tools in differentiating between human and AI-generated text | 2023 | Hasan Ragab et al. | [link](https://edintegrity.biomedcentral.com/articles/10.1007/s40979-023-00140-5) | Оценка эффективности инструментов детекции ИИ-контента - можем сравнить |
| AI Generated Text Detection Using Instruction Fine-tuned Large Language and Transformer-Based Models | 2025 | Adaku Uchendu et al. | [link](https://arxiv.org/html/2507.05157) | Детекция ИИ-генерированных текстов с использованием дообученных больших языковых моделей - можем сравнить |
| New AI classifier for indicating AI-written text | 2023 | OpenAI Team | [link](https://openai.com/index/new-ai-classifier-for-indicating-ai-written-text/) | Новый классификатор OpenAI для идентификации ИИ-генерированного текста - можем сравнить |
| Part of speech tagging: a systematic review of deep learning and machine learning approaches | 2022 | Ranjan Kumar Mohapatra et al. | [link](https://journalofbigdata.springeropen.com/articles/10.1186/s40537-022-00561-y) | Систематический обзор подходов глубокого обучения к разметке частей речи - не можем сравнить |
| Classification Between Machine Translated Text and Original Text By Part Of Speech Tagging Representation | 2020 | Abdullah Irawan et al. | [link](https://ieeexplore.ieee.org/document/9260059/) | Классификация между машинно-переведенным и оригинальным текстом на основе POS-разметки - можем сравнить |
| Understanding Part-of-Speech Tagging in NLP: Techniques and Applications | 2022 | Shiksha Editorial Team | [link](https://www.shiksha.com/online-courses/articles/pos-tagging-in-nlp/) | Понимание POS-разметки в NLP: техники и применения - не можем сравнить |
| Part-of-Speech tagging enhancement to natural language processing for Thai wh-question classification with deep learning | 2021 | Kanyakorn Veerasarn et al. | [link](https://www.sciencedirect.com/science/article/pii/S2405844021023197) | Улучшение классификации вопросов с помощью POS-разметки - не можем сравнить |
| How To Apply Advanced Part of Speech Tagging to your ML Models with GPT and Other LLMs | 2023 | Justin Swansburg | [link](https://medium.com/better-programming/how-to-incorporate-llms-into-your-machine-learning-pipelines-part-i-7caa9541fdbd) | Применение продвинутой POS-разметки в ML-моделях с GPT - не можем сравнить |
| Language modelling for Russian and English using words and classes | 2002 | Michael Riley et al. | [link](https://www.sciencedirect.com/science/article/abs/pii/S0885230802000475) | Языковое моделирование для русского и английского языков - не можем сравнить |
| DetectGPT: Zero-shot machine-generated text detection using probability curvature | 2023 | Eric Mitchell et al. | [link](https://arxiv.org/abs/2301.11305) | Zero-shot детекция машинно-генерированного текста с использованием кривизны вероятности - можем сравнить |
| Spotting LLMs with binoculars: Zero-shot detection of machine-generated text | 2024 | Abhimanyu Hans et al. | [link](https://arxiv.org/abs/2401.12070) | Zero-shot детекция машинно-генерированного текста методом Binoculars - можем сравнить |
| DNA-GPT: Divergent N-gram analysis for training-free detection of GPT-generated text | 2023 | Xianjun Yang et al. | [link](https://arxiv.org/abs/2305.17359) | Анализ расходящихся N-грамм для детекции GPT-генерированного текста - можем сравнить |
| Fast-DetectGPT: Efficient zero-shot detection of machine-generated text via conditional probability curvature | 2024 | Guangsheng Bao et al. | [link](https://arxiv.org/abs/2310.05130) | Эффективная zero-shot детекция машинно-генерированного текста - можем сравнить |
| Ghostbuster: detecting text ghostwritten by large language models | 2024 | Vivek Verma et al. | [link](https://arxiv.org/abs/2305.15047) | Детекция текстов, написанных большими языковыми моделями - можем сравнить |
| AI-generated text detection and classification based on BERT deep learning algorithm | 2024 | Haozhe Wang et al. | [link](https://arxiv.org/abs/2405.16422) | Детекция и классификация ИИ-генерированных текстов на основе BERT - можем сравнить |
| HowkGPT: Investigating the detection of ChatGPT-generated university student homework through context-aware perplexity analysis | 2023 | Christos Vasilatos et al. | [link](https://arxiv.org/abs/2305.18226) | Исследование детекции домашних заданий, сгенерированных ChatGPT - можем сравнить |
| Automatic detection of machine generated text: A critical survey | 2020 | Ganesh Jawahar et al. | [link](https://arxiv.org/abs/2011.01314) | Критический обзор автоматической детекции машинно-генерированных текстов - не можем сравнить |
| Real or fake text?: Investigating human ability to detect boundaries between human-written and machine-generated text | 2023 | Liam Dugan et al. | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26522) | Исследование способности человека обнаруживать границы между человеческими и машинными текстами - не можем сравнить |
| Multihead span-based detector for AI-generated fragments in scientific papers | 2024 | Gleb Gritsai et al. | [link](https://aclanthology.org/2024.sdp-1.5/) | Многоголовый детектор ИИ-генерированных фрагментов в научных статьях - можем сравнить |
| SemEval-2024 Task 8: Multidomain, multimodel and multilingual machine-generated text detection | 2024 | Yuxia Wang et al. | [link](https://arxiv.org/abs/2404.14183) | Многодоменная, многомодельная и многоязычная детекция машинно-генерированных текстов - можем сравнить |
| ChatGPT: A comprehensive review on background, applications, key challenges, bias, ethics, limitations and future scope | 2023 | Partha Pratim Ray | [link](https://www.sciencedirect.com/science/article/pii/S2542660523000318) | Комплексный обзор ChatGPT: применения, вызовы, этика и ограничения - не можем сравнить |
| Artificially generated text fragments search in academic documents | 2023 | Gleb M. Gritsay et al. | [link](https://link.springer.com/article/10.1134/S106456242360234X) | Поиск искусственно генерированных фрагментов текста в академических документах - можем сравнить |
| A method of multilingual summarization for scientific documents | 2022 | Konstantin Grashchenkov et al. | [link](https://ieeexplore.ieee.org/document/10076346) | Метод многоязычного реферирования научных документов - не можем сравнить |
| Team apteam at PAN: LLM adapters for various datasets | 2024 | Galina Boeva et al. | [link](https://ceur-ws.org/Vol-3740/paper-161.pdf) | LLM адаптеры для различных датасетов - можем сравнить |
| Generative AI models with their full reveal | 2024 | Yury Chekhovich et al. | [link](https://ieeexplore.ieee.org/document/10676543) | Генеративные ИИ модели с полным раскрытием - не можем сравнить |
| KenLM: Faster and smaller language model queries | 2011 | Kenneth Heafield | [link](https://aclanthology.org/W11-2123/) | Более быстрые и компактные запросы языковых моделей - не можем сравнить |
| Kneser-Ney smoothing on expected counts | 2014 | Hui Zhang, David Chiang | [link](https://aclanthology.org/P14-1146/) | Сглаживание Кнезера-Нея для ожидаемых частот - не можем сравнить |
| LLaMA: Open and efficient foundation language models | 2023 | Hugo Touvron et al. | [link](https://arxiv.org/abs/2302.13971) | Открытые и эффективные базовые языковые модели - не можем сравнить |
| Mistral 7B | 2023 | Albert Jiang et al. | [link](https://arxiv.org/abs/2310.06825) | Языковая модель Mistral 7B - не можем сравнить |
| ChatGPT 'contamination': Estimating the prevalence of LLMs in the scholarly literature | 2024 | Andrew Gray | [link](https://arxiv.org/abs/2403.16887) | Оценка распространенности LLM в научной литературе - не можем сравнить |
| Language models are unsupervised multitask learners | 2019 | Alec Radford et al. | [link](https://d4mucfpksywv.cloudfront.net/better-language-models/language_models_are_unsupervised_multitask_learners.pdf) | Языковые модели как неконтролируемые многозадачные ученики - не можем сравнить |
| BART: Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension | 2020 | Mike Lewis et al. | [link](https://arxiv.org/abs/1910.13461) | BART: Предварительное обучение с шумоподавлением для генерации естественного языка - не можем сравнить |
| BLOOM: A 176B-parameter open-access multilingual language model | 2022 | Teven Le Scao et al. | [link](https://arxiv.org/abs/2211.05100) | BLOOM: многоязычная языковая модель с открытым доступом - не можем сравнить |
| OPT: Open Pre-trained Transformer language models | 2022 | Susan Zhang et al. | [link](https://arxiv.org/abs/2205.01068) | OPT: открытые предварительно обученные трансформеры - не можем сравнить |